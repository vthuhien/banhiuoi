# -*- coding: utf-8 -*-
"""Crawl_Web.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZQT0OI1GEVypYwXtAjiOlP6mwS5YvrDq
"""

!pip install requests beautifulsoup4

!pip install requests

"""### Web Crawl
* This is a auto process to extract infomations of website and store it in a suitable form.
* We will extract data from any website. We choose the [website](https://www.formula1.com/) about the races and the rankings of the racers
* Crawling website is a common activity in working and contruction process with machine learning module. They also collect more data to increase the precision of this machine learning
* So, Knowing how to crawl data in website that very necessary
"""

import requests
from bs4 import BeautifulSoup

url = 'https://www.formula1.com/en/results/2024/drivers'
response = requests.get(url)
# print(response)

a = response.content
print(a)

# a = soup.div
# b = soup.find('div', class_='f1-container container')
# print(a.prettify())

url = 'https://www.formula1.com/en/results/2024/drivers'
response = requests.get(url)

if response.status_code == 200:
  #get out data
  soup = BeautifulSoup(response.content, 'html.parser') #.content = file html #convert data into DOM html to easily get out data
  table = soup.find('table', class_ = 'f1-table f1-table-with-data w-full')
  # print(table.prettify())

  #extract the table rows(tr) of html
  row = table.find_all('tr')
  result = []
  for index,a in enumerate(row):
    # print(a.prettify())
    column = a.find_all('p')
    # print(column[0])
    # for inx, col in enumerate(column):
      # position = column[0].text.strip()
      # print(position)

      # value = col.text.strip()
    value = [col.text.strip() for col in column] #use list comprehension to save result to list
    result.append(value)

  # print(result)
  unique_result = set(tuple(item) for item in result)
  for item in unique_result:
      print(item)



